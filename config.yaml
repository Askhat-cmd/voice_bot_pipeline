# Configuration for the Voice Bot Pipeline (SAG v2.0 Optimized)

# Logging configuration
logging:
  level: "INFO" # DEBUG, INFO, WARNING, ERROR
  log_file: "pipeline.log"

# Global pipeline settings
pipeline:
  # YouTube subtitles download settings (сохраняем для анализа)
  subtitles:
    output_dir: "data/raw_subtitles"  # Сохраняем сырые субтитры
    # Options: "ru", "en", etc.
    language: "ru"

  # Text processing settings - DIRECT TO SAG v2.0
  text_processing:
    output_dir: "data/sag_final"  # Прямо в финальную папку SAG v2.0

  # Directory for pipeline run results and logs
  results_dir: "data/sag_final"  # Результаты тоже в SAG v2.0

# Vector Database settings (ChromaDB)
vector_db:
  # Путь к директории с базой данных ChromaDB
  db_path: "data/chromadb"
  
  # Префикс для имен коллекций
  collection_prefix: "sag_v2"
  
  # Автоматическая индексация после обработки
  auto_index: true  # Установите true для автоматической индексации
  
  # Уровни индексации (documents, blocks, graph_entities)
  index_levels:
    - "documents"
    - "blocks"
    - "graph_entities"
  
  # Настройки эмбеддингов
  embedding:
    model: "text-embedding-3-small"  # OpenAI модель
    dimension: 1536  # Размерность эмбеддингов
  
  # Размер батча для индексации
  batch_size: 100
  
  # Настройки для работы с ограниченной квотой (ОПТИМИЗИРОВАНО)
  rate_limiting:
    # Максимальный размер чанка для одного запроса к API
    # OpenAI лимит: до 2048 текстов в одном запросе
    # ВАЖНО: Используйте максимальный размер батча для минимизации количества запросов
    # Это эффективнее параллельных запросов при ограниченной квоте RPM
    chunk_size: 2048  # Максимальный размер для минимизации запросов
    # Задержка между запросами в секундах
    # Для базовых планов OpenAI: обычно 3-5 RPM, поэтому нужна задержка ~12-20 секунд
    # Для платных планов можно уменьшить до 1-2 секунд
    delay_between_requests: 15  # Безопасная задержка для базовых планов
    # Максимальное количество попыток при ошибке rate limit
    max_retries: 5
    # Начальная задержка при retry в секундах (экспоненциально увеличивается)
    retry_delay: 2
    # Максимальная задержка при retry в секундах
    max_retry_delay: 60
    # Количество параллельных запросов
    # ВАЖНО: Для базовых планов OpenAI (3-5 RPM) используйте 1 (последовательная обработка)
    # Параллелизм быстро исчерпывает лимиты RPM и приводит к ошибкам 429
    # Для платных планов с высокими лимитами можно использовать 2-3
    max_workers: 1  # Последовательная обработка для избежания rate limits
  
  # Настройки для обработки длинных текстов
  text_processing:
    # Максимальное количество токенов на один текст (лимит OpenAI: 8192, оставляем запас)
    max_tokens_per_text: 8000
    # Перекрытие между чанками при разбиении длинных текстов (в токенах)
    chunk_overlap: 100