#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Vector Indexer for indexing SAG v2.0 data into ChromaDB
"""

import json
import logging
import time
from pathlib import Path
from typing import Dict, List, Any, Optional

from .chromadb_manager import VectorDBManager
from .embedding_service import EmbeddingService

logger = logging.getLogger(__name__)


class VectorIndexer:
    """–ò–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è SAG v2.0 –¥–∞–Ω–Ω—ã—Ö –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É"""
    
    def __init__(
        self, 
        db_manager: VectorDBManager,
        embedding_service: EmbeddingService,
        batch_size: int = 100
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞
        
        Args:
            db_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä ChromaDB
            embedding_service: –°–µ—Ä–≤–∏—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        self.db_manager = db_manager
        self.embedding_service = embedding_service
        self.batch_size = batch_size
        
        logger.info("‚úÖ VectorIndexer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def index_document(self, sag_data: Dict[str, Any]) -> bool:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Ü–µ–ª–∏–∫–æ–º (document_summary + document_title)
        
        Args:
            sag_data: –î–∞–Ω–Ω—ã–µ SAG v2.0
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            collection = self.db_manager.get_or_create_collection("documents")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            document_title = sag_data.get("document_title", "")
            document_summary = sag_data.get("document_summary", "")
            text_to_embed = f"{document_title}\n{document_summary}".strip()
            
            if not text_to_embed:
                logger.warning("–ü—É—Å—Ç–æ–π –¥–æ–∫—É–º–µ–Ω—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é")
                return False
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            embedding = self.embedding_service.create_embedding(text_to_embed)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata = sag_data.get("document_metadata", {})
            doc_metadata = {
                "video_id": metadata.get("video_id", ""),
                "document_title": document_title,
                "published_date": metadata.get("published_date", ""),
                "source_url": metadata.get("source_url", ""),
                "language": metadata.get("language", "ru"),
                "domain": metadata.get("domain", ""),
                "collection_target": metadata.get("collection_target", ""),
                "main_topics": ", ".join(metadata.get("main_topics", [])),
                "difficulty_level": metadata.get("difficulty_level", ""),
                "total_blocks": str(metadata.get("total_blocks", 0)),
                "schema_version": metadata.get("schema_version", "2.0"),
            }
            
            # ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
            doc_id = f"doc_{metadata.get('video_id', 'unknown')}"
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            collection.add(
                ids=[doc_id],
                embeddings=[embedding],
                documents=[text_to_embed],
                metadatas=[doc_metadata]
            )
            
            logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω: {doc_id}")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}", exc_info=True)
            return False
    
    def index_blocks(self, sag_data: Dict[str, Any]) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –≤—Å–µ –±–ª–æ–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
        Args:
            sag_data: –î–∞–Ω–Ω—ã–µ SAG v2.0
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤
        """
        try:
            collection = self.db_manager.get_or_create_collection("blocks")
            blocks = sag_data.get("blocks", [])
            
            if not blocks:
                logger.warning("–ù–µ—Ç –±–ª–æ–∫–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
                return 0
            
            video_id = sag_data.get("document_metadata", {}).get("video_id", "unknown")
            document_title = sag_data.get("document_title", "")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∏
            texts_to_embed = []
            block_ids = []
            metadatas_list = []
            
            for block in blocks:
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
                block_title = block.get("title", "")
                block_summary = block.get("summary", "")
                block_content = block.get("content", "")
                keywords = ", ".join(block.get("keywords", []))
                
                text_to_embed = f"{block_title}\n{block_summary}\n{keywords}\n{block_content}".strip()
                
                if not text_to_embed:
                    continue
                
                texts_to_embed.append(text_to_embed)
                block_id = block.get("block_id", f"{video_id}_unknown")
                block_ids.append(block_id)
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                safety = block.get("safety", {})
                has_safety_warnings = bool(
                    safety.get("contraindications") or 
                    safety.get("when_to_stop") or
                    safety.get("when_to_seek_professional_help")
                )
                
                metadata = {
                    "block_id": block_id,
                    "video_id": video_id,
                    "document_title": document_title,
                    "published_date": sag_data.get("document_metadata", {}).get("published_date", ""),
                    "start": block.get("start", ""),
                    "end": block.get("end", ""),
                    "block_type": block.get("block_type", ""),
                    "emotional_tone": block.get("emotional_tone", ""),
                    "conceptual_depth": block.get("conceptual_depth", ""),
                    "complexity_score": str(block.get("complexity_score", 0.0)),
                    "collection_target": sag_data.get("document_metadata", {}).get("collection_target", ""),
                    "youtube_link": block.get("youtube_link", ""),
                    "graph_entities": ", ".join(block.get("graph_entities", [])[:10]),  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    # –ù–æ–≤—ã–µ —Ñ–ª–∞–≥–∏ –¥–ª—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤ SAG v2.0
                    "has_safety_warnings": str(has_safety_warnings),
                    "has_causal_chains": str(bool(block.get("causal_chains"))),
                    "has_case_studies": str(bool(block.get("case_studies"))),
                    "has_prerequisites": str(bool(block.get("prerequisites", {}).get("prerequisites"))),
                    "has_concept_hierarchy": str(bool(block.get("concept_hierarchy"))),
                }
                metadatas_list.append(metadata)
            
            if not texts_to_embed:
                logger.warning("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
                return 0
            
            # –ë–∞—Ç—á-—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embeddings = self.embedding_service.create_embeddings_batch(texts_to_embed)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é –±–∞—Ç—á–∞–º–∏
            indexed_count = 0
            for i in range(0, len(block_ids), self.batch_size):
                batch_ids = block_ids[i:i + self.batch_size]
                batch_embeddings = embeddings[i:i + self.batch_size]
                batch_documents = texts_to_embed[i:i + self.batch_size]
                batch_metadatas = metadatas_list[i:i + self.batch_size]
                
                collection.add(
                    ids=batch_ids,
                    embeddings=batch_embeddings,
                    documents=batch_documents,
                    metadatas=batch_metadatas
                )
                indexed_count += len(batch_ids)
            
            logger.info(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –±–ª–æ–∫–æ–≤: {indexed_count}/{len(blocks)}")
            return indexed_count
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –±–ª–æ–∫–æ–≤: {e}", exc_info=True)
            return 0
    
    def index_graph_entities(self, sag_data: Dict[str, Any]) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        
        Args:
            sag_data: –î–∞–Ω–Ω—ã–µ SAG v2.0
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
        """
        try:
            collection = self.db_manager.get_or_create_collection("graph_entities")
            blocks = sag_data.get("blocks", [])
            
            if not blocks:
                logger.warning("–ù–µ—Ç –±–ª–æ–∫–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≥—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–µ–π")
                return 0
            
            video_id = sag_data.get("document_metadata", {}).get("video_id", "unknown")
            document_title = sag_data.get("document_title", "")
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            entity_contexts: Dict[str, List[str]] = {}
            
            for block in blocks:
                graph_entities = block.get("graph_entities", [])
                block_title = block.get("title", "")
                block_summary = block.get("summary", "")
                block_id = block.get("block_id", "")
                
                for entity in graph_entities:
                    if entity not in entity_contexts:
                        entity_contexts[entity] = []
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–ª–æ–∫–∞
                    context = f"–ë–ª–æ–∫: {block_title}\n{block_summary}"
                    entity_contexts[entity].append(context)
            
            if not entity_contexts:
                logger.warning("–ù–µ—Ç –≥—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
                return 0
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            texts_to_embed = []
            entity_ids = []
            metadatas_list = []
            
            for entity, contexts in entity_contexts.items():
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
                context_text = "\n\n".join(contexts[:5])  # –ú–∞–∫—Å–∏–º—É–º 5 –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
                text_to_embed = f"–ì—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç—å: {entity}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context_text}".strip()
                
                texts_to_embed.append(text_to_embed)
                entity_id = f"entity_{video_id}_{entity}"
                entity_ids.append(entity_id)
                
                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {
                    "entity_name": entity,
                    "video_id": video_id,
                    "document_title": document_title,
                    "published_date": sag_data.get("document_metadata", {}).get("published_date", ""),
                    "frequency": str(len(contexts)),
                    "domain": sag_data.get("document_metadata", {}).get("domain", ""),
                }
                metadatas_list.append(metadata)
            
            # –ë–∞—Ç—á-—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embeddings = self.embedding_service.create_embeddings_batch(texts_to_embed)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            indexed_count = 0
            for i in range(0, len(entity_ids), self.batch_size):
                batch_ids = entity_ids[i:i + self.batch_size]
                batch_embeddings = embeddings[i:i + self.batch_size]
                batch_documents = texts_to_embed[i:i + self.batch_size]
                batch_metadatas = metadatas_list[i:i + self.batch_size]
                
                collection.add(
                    ids=batch_ids,
                    embeddings=batch_embeddings,
                    documents=batch_documents,
                    metadatas=batch_metadatas
                )
                indexed_count += len(batch_ids)
            
            logger.info(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –≥—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–µ–π: {indexed_count}")
            return indexed_count
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≥—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–µ–π: {e}", exc_info=True)
            return 0
    
    def index_knowledge_graph(self, sag_data: Dict[str, Any]) -> int:
        """
        üöÄ –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç Knowledge Graph (—É–∑–ª—ã –∏ —Å–≤—è–∑–∏) –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        
        Args:
            sag_data: –î–∞–Ω–Ω—ã–µ SAG v2.0 —Å knowledge_graph
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ –≥—Ä–∞—Ñ–∞
        """
        try:
            knowledge_graph = sag_data.get("knowledge_graph")
            if not knowledge_graph:
                logger.warning("Knowledge Graph –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö")
                return 0
            
            collection = self.db_manager.get_or_create_collection(
                name="knowledge_graph",
                metadata={"description": "Knowledge Graph nodes and edges for AI bot"}
            )
            
            nodes = knowledge_graph.get("nodes", [])
            edges = knowledge_graph.get("edges", [])
            video_id = sag_data.get("document_metadata", {}).get("video_id", "unknown")
            
            if not nodes:
                logger.warning("–ù–µ—Ç —É–∑–ª–æ–≤ –≤ Knowledge Graph")
                return 0
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å —Å–≤—è–∑–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            edges_by_node = {}
            for edge in edges:
                from_id = edge.get("from_id")
                to_id = edge.get("to_id")
                if from_id not in edges_by_node:
                    edges_by_node[from_id] = []
                edges_by_node[from_id].append(edge)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —É–∑–ª–æ–≤
            texts_to_embed = []
            node_ids = []
            metadatas_list = []
            
            for node in nodes:
                node_id = node.get("id", "")
                node_name = node.get("name", "")
                node_type = node.get("node_type", "CONCEPT")
                description = node.get("description", "")
                
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–≤—è–∑—è—Ö
                outgoing_edges = edges_by_node.get(node_id, [])
                connections_info = []
                for edge in outgoing_edges[:5]:  # –ú–∞–∫—Å–∏–º—É–º 5 —Å–≤—è–∑–µ–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                    target_node = next((n for n in nodes if n.get("id") == edge.get("to_id")), None)
                    if target_node:
                        connections_info.append(
                            f"{edge.get('edge_type', 'RELATED_TO')}: {target_node.get('name', '')}"
                        )
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
                connections_text = "\n".join(connections_info) if connections_info else "–ù–µ—Ç —Å–≤—è–∑–µ–π"
                text_to_embed = (
                    f"–£–∑–µ–ª Knowledge Graph: {node_name}\n"
                    f"–¢–∏–ø: {node_type}\n"
                    f"–û–ø–∏—Å–∞–Ω–∏–µ: {description}\n"
                    f"–°–≤—è–∑–∏:\n{connections_text}"
                ).strip()
                
                texts_to_embed.append(text_to_embed)
                full_node_id = f"kg_node_{video_id}_{node_id}"
                node_ids.append(full_node_id)
                
                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —É–∑–ª–∞
                metadata = {
                    "node_id": node_id,
                    "node_name": node_name,
                    "node_type": node_type,
                    "video_id": video_id,
                    "document_title": sag_data.get("document_title", ""),
                    "description": description[:200] if description else "",  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
                    "connections_count": str(len(outgoing_edges)),
                    "source": ",".join(node.get("metadata", {}).get("source", []) if isinstance(node.get("metadata", {}).get("source"), list) else [node.get("metadata", {}).get("source", "")])
                }
                metadatas_list.append(metadata)
            
            # –ë–∞—Ç—á-—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embeddings = self.embedding_service.create_embeddings_batch(texts_to_embed)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            indexed_count = 0
            for i in range(0, len(node_ids), self.batch_size):
                batch_ids = node_ids[i:i + self.batch_size]
                batch_embeddings = embeddings[i:i + self.batch_size]
                batch_documents = texts_to_embed[i:i + self.batch_size]
                batch_metadatas = metadatas_list[i:i + self.batch_size]
                
                collection.add(
                    ids=batch_ids,
                    embeddings=batch_embeddings,
                    documents=batch_documents,
                    metadatas=batch_metadatas
                )
                indexed_count += len(batch_ids)
            
            logger.info(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ —É–∑–ª–æ–≤ Knowledge Graph: {indexed_count}")
            logger.info(f"üìä –í—Å–µ–≥–æ —Å–≤—è–∑–µ–π –≤ –≥—Ä–∞—Ñ–µ: {len(edges)}")
            return indexed_count
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ Knowledge Graph: {e}", exc_info=True)
            return 0
    
    def index_sag_file(self, json_path: Path, index_levels: List[str] = None) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è SAG v2.0 JSON —Ñ–∞–π–ª–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        Args:
            json_path: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É
            index_levels: –°–ø–∏—Å–æ–∫ —É—Ä–æ–≤–Ω–µ–π –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (documents, blocks, graph_entities)
                         –ï—Å–ª–∏ None, –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –≤—Å–µ —É—Ä–æ–≤–Ω–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        """
        if index_levels is None:
            index_levels = ["documents", "blocks", "graph_entities", "knowledge_graph"]
        
        start_time = time.time()  # ‚è±Ô∏è –ù–∞—á–∞–ª–æ –æ—Ç—Å—á–µ—Ç–∞
        
        results = {
            "file": str(json_path),
            "success": False,
            "indexed": {
                "documents": 0,
                "blocks": 0,
                "graph_entities": 0,
                "knowledge_graph": 0
            }
        }
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ JSON
            with open(json_path, 'r', encoding='utf-8') as f:
                sag_data = json.load(f)
            
            logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {json_path.name}")
            
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö
            if "documents" in index_levels:
                if self.index_document(sag_data):
                    results["indexed"]["documents"] = 1
            
            if "blocks" in index_levels:
                blocks_count = self.index_blocks(sag_data)
                results["indexed"]["blocks"] = blocks_count
            
            if "graph_entities" in index_levels:
                entities_count = self.index_graph_entities(sag_data)
                results["indexed"]["graph_entities"] = entities_count
            
            # üöÄ –ù–û–í–û–ï: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è Knowledge Graph
            if "knowledge_graph" in index_levels:
                kg_nodes_count = self.index_knowledge_graph(sag_data)
                results["indexed"]["knowledge_graph"] = kg_nodes_count
            
            results["success"] = True
            
            # –ü–æ–¥—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            elapsed = time.time() - start_time
            total_items = sum([
                results["indexed"]["documents"],
                results["indexed"]["blocks"],
                results["indexed"]["graph_entities"],
                results["indexed"]["knowledge_graph"]
            ])
            
            logger.info(f"‚úÖ –§–∞–π–ª –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω: {json_path.name}")
            logger.info(f"‚ö° –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.2f}s "
                       f"({total_items} —ç–ª–µ–º–µ–Ω—Ç–æ–≤, {total_items/elapsed:.1f} —ç–ª/—Å–µ–∫)" if total_items > 0 else f"‚ö° –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.2f}s")
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ {json_path}: {e}", exc_info=True)
            logger.error(f"‚è±Ô∏è –í—Ä–µ–º—è –¥–æ –æ—à–∏–±–∫–∏: {elapsed:.2f}s")
            results["error"] = str(e)
        
        return results

