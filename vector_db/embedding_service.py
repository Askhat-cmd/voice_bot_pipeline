#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Embedding Service for creating vector embeddings using Sentence-Transformers
"""

import logging
import os
from typing import List, Optional

from sentence_transformers import SentenceTransformer
from env_utils import load_env

logger = logging.getLogger(__name__)


class EmbeddingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ Sentence-Transformers"""
    
    def __init__(self, model: Optional[str] = None, device: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        
        Args:
            model: –ú–æ–¥–µ–ª—å Sentence-Transformers (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –±–µ—Ä–µ—Ç—Å—è –∏–∑ SENTENCE_TRANSFORMERS_MODEL –≤ .env, –∏–Ω–∞—á–µ intfloat/multilingual-e5-large)
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ('cuda', 'cpu', 'mps' –∏–ª–∏ None –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞)
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ
        load_env()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞, –ø–æ—Ç–æ–º –∏–∑ env, –ø–æ—Ç–æ–º –¥–µ—Ñ–æ–ª—Ç
        if model is None:
            model = os.getenv("SENTENCE_TRANSFORMERS_MODEL", "intfloat/multilingual-e5-large")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞, –ø–æ—Ç–æ–º –∏–∑ env, –ø–æ—Ç–æ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if device is None:
            device = os.getenv("SENTENCE_TRANSFORMERS_DEVICE", None)  # None = –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä
        
        logger.info(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Sentence-Transformers: {model}")
        if device:
            logger.info(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device} (—è–≤–Ω–æ —É–∫–∞–∑–∞–Ω–æ)")
        else:
            logger.info(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä (GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ CPU)")
        
        try:
            self.model = SentenceTransformer(model, device=device)
            self.embedding_dim = self.model.get_sentence_embedding_dimension()
            actual_device = str(next(self.model.parameters()).device)
            logger.info(f"‚úÖ EmbeddingService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é: {model}, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {self.embedding_dim}, —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {actual_device}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ {model}: {e}")
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å Sentence-Transformers: {e}") from e
    
    def create_embedding(self, text: str) -> List[float]:
        """
        –°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª (–≤–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞)
        """
        if not text or not text.strip():
            logger.warning("–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥–∞–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞")
            return [0.0] * self.embedding_dim
        
        text = text.strip()
        
        try:
            # Sentence-Transformers –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
            # –ú–æ–¥–µ–ª—å —Å–∞–º–∞ –æ–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–æ–±—ã—á–Ω–æ –¥–æ 512 —Ç–æ–∫–µ–Ω–æ–≤)
            embedding = self.model.encode(text, convert_to_numpy=True)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥: {e}") from e
    
    def create_embeddings_batch(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """
        –°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –±–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∞)
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 32)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        if not texts:
            return []
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å—ã
        valid_texts = []
        valid_indices = []
        for i, text in enumerate(texts):
            if text and text.strip():
                valid_texts.append(text.strip())
                valid_indices.append(i)
        
        if not valid_texts:
            logger.warning("–í—Å–µ —Ç–µ–∫—Å—Ç—ã –ø—É—Å—Ç—ã–µ")
            return [[0.0] * self.embedding_dim] * len(texts)
        
        logger.info(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(valid_texts)} —Ç–µ–∫—Å—Ç–æ–≤ (–±–∞—Ç—á-—Ä–µ–∂–∏–º, batch_size={batch_size})")
        
        try:
            # Sentence-Transformers —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á–∏ –ª–æ–∫–∞–ª—å–Ω–æ
            embeddings = self.model.encode(
                valid_texts,
                batch_size=batch_size,
                convert_to_numpy=True,
                show_progress_bar=False
            )
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å —É—á–µ—Ç–æ–º –ø—É—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            result = []
            embedding_idx = 0
            for i, original_text in enumerate(texts):
                if i in valid_indices:
                    result.append(embeddings[embedding_idx].tolist())
                    embedding_idx += 1
                else:
                    result.append([0.0] * self.embedding_dim)  # –ü—É—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã –ø–æ–ª—É—á–∞—é—Ç –Ω—É–ª–µ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
            
            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(valid_texts)} —Ç–µ–∫—Å—Ç–æ–≤")
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –±–∞—Ç—á–µ–º: {e}")
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {e}") from e
    
    @property
    def dimension(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        return self.embedding_dim
