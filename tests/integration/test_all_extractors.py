"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤.

–ü—Ä–æ–≤–µ—Ä—è—é—Ç —Å–æ–≤–º–µ—Å—Ç–Ω—É—é —Ä–∞–±–æ—Ç—É:
- TerminologyValidator
- NeurostalkingPatternExtractor
- CausalChainExtractor
- ConceptHierarchyExtractor
"""

import pytest
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
project_root = Path(__file__).resolve().parents[3]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from voice_bot_pipeline.text_processor.validators.terminology_validator import TerminologyValidator
from voice_bot_pipeline.text_processor.extractors.neurostalking_pattern_extractor import NeurostalkingPatternExtractor
from voice_bot_pipeline.text_processor.extractors.causal_chain_extractor import CausalChainExtractor
from voice_bot_pipeline.text_processor.extractors.concept_hierarchy_extractor import ConceptHierarchyExtractor

from voice_bot_pipeline.tests.fixtures.real_sarsekenov_texts import (
    TRIADA_TRANSFORMATION_TEXT,
    ATTENTION_FIELD_TEXT,
    HIERARCHY_PRACTICES_TEXT,
    MIXED_TERMINOLOGY_TEXT,
    GENERIC_PSYCHOLOGY_TEXT,
    TEXTS_METADATA
)


@pytest.fixture
def validator():
    """–§–∏–∫—Å—Ç—É—Ä–∞ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞"""
    return TerminologyValidator()


@pytest.fixture
def pattern_extractor(validator):
    """–§–∏–∫—Å—Ç—É—Ä–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    return NeurostalkingPatternExtractor(terminology_validator=validator)


@pytest.fixture
def causal_chain_extractor(validator):
    """–§–∏–∫—Å—Ç—É—Ä–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ —Ü–µ–ø–æ—á–µ–∫"""
    return CausalChainExtractor(terminology_validator=validator)


@pytest.fixture
def hierarchy_extractor(validator):
    """–§–∏–∫—Å—Ç—É—Ä–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –∏–µ—Ä–∞—Ä—Ö–∏–∏"""
    return ConceptHierarchyExtractor(terminology_validator=validator)


class TestFullPipeline:
    """–¢–µ—Å—Ç—ã –ø–æ–ª–Ω–æ–≥–æ pipeline –≤—Å–µ—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤"""
    
    def test_triada_transformation_full_pipeline(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """
        –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline –Ω–∞ —Ç–µ–∫—Å—Ç–µ –æ —Ç—Ä–∏–∞–¥–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
        1. –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—Ö–æ–¥–∏—Ç
        2. –í—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –∏–∑–≤–ª–µ–∫–∞—é—Ç –¥–∞–Ω–Ω—ã–µ
        3. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–≤–º–µ—Å—Ç–∏–º—ã –º–µ–∂–¥—É —Å–æ–±–æ–π
        """
        text = TRIADA_TRANSFORMATION_TEXT
        metadata = TEXTS_METADATA["TRIADA_TRANSFORMATION_TEXT"]
        
        # –®–ê–ì 1: –í–ê–õ–ò–î–ê–¶–ò–Ø
        validation = validator.validate_text(text)
        
        assert validation.is_valid, f"Validation failed: {validation.reason}"
        assert validation.metrics['density'] >= 0.15, "Density too low"
        
        print(f"\n‚úÖ VALIDATION PASSED")
        print(f"   Density: {validation.metrics['density']:.1%}")
        print(f"   Entities: {len(validation.sarsekenov_entities)}")
        
        # –®–ê–ì 2: –ü–ê–¢–¢–ï–†–ù–´
        patterns_result = pattern_extractor.extract(text)
        
        assert patterns_result['valid'], f"Patterns failed: {patterns_result.get('reason')}"
        assert len(patterns_result['patterns']) > 0, "No patterns extracted"
        
        print(f"\n‚úÖ PATTERNS EXTRACTED")
        print(f"   Total: {len(patterns_result['patterns'])}")
        for p in patterns_result['patterns']:
            print(f"   - {p['pattern_category']}: {p['pattern_name']}")
        
        # –®–ê–ì 3: –¶–ï–ü–û–ß–ö–ò
        chains_result = causal_chain_extractor.extract(text)
        
        assert chains_result['valid'], f"Chains failed: {chains_result.get('reason')}"
        assert len(chains_result['chains']) > 0, "No chains extracted"
        
        print(f"\n‚úÖ CAUSAL CHAINS EXTRACTED")
        print(f"   Total: {len(chains_result['chains'])}")
        for c in chains_result['chains']:
            print(f"   - {c['process_category']}: {len(c['stages'])} stages")
        
        # –®–ê–ì 4: –ò–ï–†–ê–†–•–ò–Ø
        hierarchy_result = hierarchy_extractor.extract(text)
        
        assert hierarchy_result['valid'], f"Hierarchy failed: {hierarchy_result.get('reason')}"
        
        hierarchy = hierarchy_result['hierarchy']
        assert hierarchy['root']['name'] == metadata['expected_hierarchy_root']
        
        print(f"\n‚úÖ HIERARCHY EXTRACTED")
        print(f"   Root: {hierarchy['root']['name']}")
        print(f"   Domains: {len(hierarchy['domains'])}")
        print(f"   Practices: {len(hierarchy['practices'])}")
        
        # –®–ê–ì 5: –ü–†–û–í–ï–†–ö–ê –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
        self._check_compatibility(
            validation,
            patterns_result,
            chains_result,
            hierarchy_result,
            metadata
        )
        
        print(f"\n‚úÖ COMPATIBILITY CHECK PASSED")
    
    def test_attention_field_full_pipeline(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """–¢–µ—Å—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–µ –æ –ø–æ–ª–µ –≤–Ω–∏–º–∞–Ω–∏—è"""
        text = ATTENTION_FIELD_TEXT
        metadata = TEXTS_METADATA["ATTENTION_FIELD_TEXT"]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation = validator.validate_text(text)
        assert validation.is_valid
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns_result = pattern_extractor.extract(text)
        assert patterns_result['valid']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        categories_found = patterns_result.get('categories_found', [])
        for expected_cat in metadata['expected_patterns']:
            assert expected_cat in categories_found, \
                f"Expected pattern category '{expected_cat}' not found"
        
        print(f"\n‚úÖ ATTENTION FIELD TEST PASSED")
    
    def test_hierarchy_practices_full_pipeline(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """–¢–µ—Å—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–µ —Å –ø–æ–ª–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏–µ–π"""
        text = HIERARCHY_PRACTICES_TEXT
        metadata = TEXTS_METADATA["HIERARCHY_PRACTICES_TEXT"]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation = validator.validate_text(text)
        assert validation.is_valid
        
        # –ò–µ—Ä–∞—Ä—Ö–∏—è
        hierarchy_result = hierarchy_extractor.extract(text)
        assert hierarchy_result['valid']
        
        hierarchy = hierarchy_result['hierarchy']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–µ—Ö–Ω–∏–∫
        if metadata.get('expected_techniques'):
            assert len(hierarchy['techniques']) >= metadata['expected_techniques'], \
                f"Expected at least {metadata['expected_techniques']} techniques"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π
        if metadata.get('has_exercises'):
            assert len(hierarchy['exercises']) > 0, "Expected exercises not found"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π
            for exercise in hierarchy['exercises']:
                print(f"\n   Exercise: {exercise['name']}")
                if exercise.get('duration'):
                    print(f"     Duration: {exercise['duration']}")
                if exercise.get('frequency'):
                    print(f"     Frequency: {exercise['frequency']}")
        
        print(f"\n‚úÖ HIERARCHY PRACTICES TEST PASSED")
    
    def test_mixed_terminology_smart_mode(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """
        –¢–µ—Å—Ç SMART —Ä–µ–∂–∏–º–∞: —Ç–µ–∫—Å—Ç —Å forbidden terms –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–π—Ç–∏.
        
        –ö–†–ò–¢–ò–ß–ù–û: –í SMART —Ä–µ–∂–∏–º–µ forbidden terms –ù–ï –±–ª–æ–∫–∏—Ä—É—é—Ç —Ç–µ–∫—Å—Ç!
        """
        text = MIXED_TERMINOLOGY_TEXT
        metadata = TEXTS_METADATA["MIXED_TERMINOLOGY_TEXT"]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–π—Ç–∏ –≤ SMART —Ä–µ–∂–∏–º–µ
        validation = validator.validate_text(text)
        
        assert validation.is_valid, \
            f"SMART mode should pass texts with forbidden terms! Reason: {validation.reason}"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ forbidden terms –Ω–∞–π–¥–µ–Ω—ã (–Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–ª–∏)
        assert len(validation.forbidden_terms_found) > 0, \
            "Expected forbidden terms in text"
        
        print(f"\n‚úÖ SMART MODE TEST PASSED")
        print(f"   Forbidden terms found: {validation.forbidden_terms_found}")
        print(f"   But text was accepted (SMART mode)")
        
        # –í—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã —Ä–∞–±–æ—Ç–∞—Ç—å
        patterns_result = pattern_extractor.extract(text)
        assert patterns_result['valid']
        
        chains_result = causal_chain_extractor.extract(text)
        assert chains_result['valid']
        
        hierarchy_result = hierarchy_extractor.extract(text)
        assert hierarchy_result['valid']
    
    def test_generic_psychology_rejected(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """–¢–µ—Å—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –æ–±—â–µ–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏"""
        text = GENERIC_PSYCHOLOGY_TEXT
        metadata = TEXTS_METADATA["GENERIC_PSYCHOLOGY_TEXT"]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –û–¢–ö–õ–û–ù–ò–¢–¨
        validation = validator.validate_text(text)
        
        assert not validation.is_valid, \
            "Generic psychology text should be rejected"
        
        assert "–ø–ª–æ—Ç–Ω–æ—Å—Ç—å" in validation.reason.lower(), \
            "Should be rejected due to low density"
        
        print(f"\n‚úÖ GENERIC PSYCHOLOGY REJECTED")
        print(f"   Reason: {validation.reason}")
        
        # –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –∏–∑–≤–ª–µ–∫–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
        patterns_result = pattern_extractor.extract(text)
        assert not patterns_result['valid']
        
        chains_result = causal_chain_extractor.extract(text)
        assert not chains_result['valid']
    
    def _check_compatibility(
        self,
        validation,
        patterns_result,
        chains_result,
        hierarchy_result,
        metadata
    ):
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤.
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
        1. –¢–µ—Ä–º–∏–Ω—ã –∏–∑ patterns –µ—Å—Ç—å –≤ validation.sarsekenov_entities
        2. –ü—Ä–∞–∫—Ç–∏–∫–∏ –∏–∑ hierarchy —Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å patterns
        3. –≠—Ç–∞–ø—ã –∏–∑ chains –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ç–µ –∂–µ —Ç–µ—Ä–º–∏–Ω—ã
        4. –ù–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –≤ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏
        """
        
        # 1. –¢–ï–†–ú–ò–ù–´ –ò–ó –ü–ê–¢–¢–ï–†–ù–û–í
        all_pattern_terms = set()
        for pattern in patterns_result['patterns']:
            all_pattern_terms.update(pattern['key_terms'])
        
        validated_entities = set(validation.sarsekenov_entities)
        
        # –í—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ validation
        # (–∏–ª–∏ –±—ã—Ç—å –æ—á–µ–Ω—å –±–ª–∏–∑–∫–∏–º–∏, –Ω–æ –∑–¥–µ—Å—å —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
        # –û—Å–ª–∞–±–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É: —Ö–æ—Ç—è –±—ã 80% —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å
        # —Ç–∞–∫ –∫–∞–∫ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –º–æ–≥—É—Ç –ø–æ-—Ä–∞–∑–Ω–æ–º—É –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å
        matches = 0
        for term in all_pattern_terms:
            if term in validated_entities:
                matches += 1
        
        match_rate = matches / len(all_pattern_terms) if all_pattern_terms else 1.0
        assert match_rate >= 0.8, \
            f"Only {match_rate:.1%} of pattern terms found in validation entities"
        
        print(f"\n   ‚úì Pattern terms compatible with validation ({match_rate:.1%})")
        
        # 2. –ü–†–ê–ö–¢–ò–ö–ò –ò–ó –ò–ï–†–ê–†–•–ò–ò
        hierarchy = hierarchy_result['hierarchy']
        hierarchy_practices = [p['name'] for p in hierarchy['practices']]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –æ–∂–∏–¥–∞–µ–º—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –Ω–∞–π–¥–µ–Ω—ã
        for expected_practice in metadata.get('expected_practices', []):
            assert expected_practice in hierarchy_practices, \
                f"Expected practice '{expected_practice}' not in hierarchy"
        
        print(f"   ‚úì Hierarchy practices match expected")
        
        # 3. –¢–ï–†–ú–ò–ù–´ –ò–ó –¶–ï–ü–û–ß–ï–ö
        all_chain_terms = set()
        for chain in chains_result['chains']:
            for stage in chain['stages']:
                all_chain_terms.update(stage['sarsekenov_terms'])
        
        # –í—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ü–µ–ø–æ—á–µ–∫ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ validation
        matches = 0
        for term in all_chain_terms:
            if term in validated_entities:
                matches += 1
        
        match_rate = matches / len(all_chain_terms) if all_chain_terms else 1.0
        assert match_rate >= 0.8, \
            f"Only {match_rate:.1%} of chain terms found in validation entities"
        
        print(f"   ‚úì Chain terms compatible with validation ({match_rate:.1%})")
        
        # 4. –ö–ê–¢–ï–ì–û–†–ò–ò –ü–ê–¢–¢–ï–†–ù–û–í vs –ö–ê–¢–ï–ì–û–†–ò–ò –¶–ï–ü–û–ß–ï–ö
        pattern_categories = set(patterns_result.get('categories_found', []))
        chain_categories = set(c['process_category'] for c in chains_result['chains'])
        
        # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ (–Ω–æ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
        overlap = pattern_categories & chain_categories
        assert len(overlap) > 0, \
            "No category overlap between patterns and chains"
        
        print(f"   ‚úì Categories overlap: {overlap}")
        
        # 5. ROOT –í –ò–ï–†–ê–†–•–ò–ò
        root_name = hierarchy['root']['name']
        assert root_name in ["–Ω–µ–π—Ä–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥", "–Ω–µ–æ-—Å—Ç–∞–ª–∫–∏–Ω–≥", "—Å—Ç–∞–ª–∫–∏–Ω–≥ —É–º–∞"], \
            f"Invalid root: {root_name}"
        
        print(f"   ‚úì Valid hierarchy root: {root_name}")


class TestPerformance:
    """–¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def test_pipeline_performance(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ pipeline —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±—ã—Å—Ç—Ä–æ"""
        import time
        
        text = TRIADA_TRANSFORMATION_TEXT
        
        start = time.time()
        
        validation = validator.validate_text(text)
        patterns_result = pattern_extractor.extract(text)
        chains_result = causal_chain_extractor.extract(text)
        hierarchy_result = hierarchy_extractor.extract(text)
        
        elapsed = time.time() - start
        
        # –ù–µ –¥–æ–ª–∂–Ω–æ –∑–∞–Ω–∏–º–∞—Ç—å –±–æ–ª—å—à–µ 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        assert elapsed < 5.0, f"Pipeline too slow: {elapsed:.2f}s"
        
        print(f"\n‚úÖ PERFORMANCE TEST PASSED")
        print(f"   Total time: {elapsed:.2f}s")
        print(f"   Validation: ~{elapsed*0.1:.2f}s")
        print(f"   Patterns: ~{elapsed*0.3:.2f}s")
        print(f"   Chains: ~{elapsed*0.3:.2f}s")
        print(f"   Hierarchy: ~{elapsed*0.3:.2f}s")


class TestTerminologyConsistency:
    """–¢–µ—Å—Ç—ã —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏"""
    
    def test_same_terms_across_extractors(
        self,
        validator,
        pattern_extractor,
        causal_chain_extractor,
        hierarchy_extractor
    ):
        """
        –í—Å–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        –∏–∑ sarsekenov_terms.json
        """
        text = TRIADA_TRANSFORMATION_TEXT
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        validation = validator.validate_text(text)
        patterns_result = pattern_extractor.extract(text)
        chains_result = causal_chain_extractor.extract(text)
        hierarchy_result = hierarchy_extractor.extract(text)
        
        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ —Ç–µ—Ä–º–∏–Ω—ã
        validated_terms = set(validation.sarsekenov_entities)
        
        pattern_terms = set()
        for p in patterns_result['patterns']:
            pattern_terms.update(p['key_terms'])
        
        chain_terms = set()
        for c in chains_result['chains']:
            for stage in c['stages']:
                chain_terms.update(stage['sarsekenov_terms'])
        
        hierarchy_terms = set()
        hierarchy = hierarchy_result['hierarchy']
        for node_list in [hierarchy['domains'], hierarchy['practices'], 
                          hierarchy['techniques']]:
            for node in node_list:
                hierarchy_terms.update(node['sarsekenov_terms'])
        
        # –û—Å–ª–∞–±–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É: —Ö–æ—Ç—è –±—ã 80% —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã
        # (—ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –º–æ–≥—É—Ç –¥–æ–±–∞–≤–ª—è—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã)
        
        p_matches = len(pattern_terms & validated_terms)
        p_rate = p_matches / len(pattern_terms) if pattern_terms else 1.0
        assert p_rate >= 0.8, \
            f"Only {p_rate:.1%} of pattern terms are validated"
        
        c_matches = len(chain_terms & validated_terms)
        c_rate = c_matches / len(chain_terms) if chain_terms else 1.0
        assert c_rate >= 0.8, \
            f"Only {c_rate:.1%} of chain terms are validated"
        
        h_matches = len(hierarchy_terms & validated_terms)
        h_rate = h_matches / len(hierarchy_terms) if hierarchy_terms else 1.0
        assert h_rate >= 0.8, \
            f"Only {h_rate:.1%} of hierarchy terms are validated"
        
        print(f"\n‚úÖ TERMINOLOGY CONSISTENCY PASSED")
        print(f"   Validated terms: {len(validated_terms)}")
        print(f"   Pattern terms: {len(pattern_terms)} (matched {p_rate:.1%})")
        print(f"   Chain terms: {len(chain_terms)} (matched {c_rate:.1%})")
        print(f"   Hierarchy terms: {len(hierarchy_terms)} (matched {h_rate:.1%})")


# ============================================================================
# HELPER: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# ============================================================================

def print_full_pipeline_results(
    text: str,
    validation,
    patterns_result,
    chains_result,
    hierarchy_result
):
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–π –ø–µ—á–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏.
    """
    print("\n" + "="*80)
    print("FULL PIPELINE RESULTS")
    print("="*80)
    
    print(f"\nüìÑ TEXT LENGTH: {len(text)} chars")
    
    print(f"\n‚úÖ VALIDATION:")
    print(f"   Valid: {validation.is_valid}")
    print(f"   Density: {validation.metrics['density']:.1%}")
    print(f"   Entities: {len(validation.sarsekenov_entities)}")
    print(f"   Forbidden terms: {validation.forbidden_terms_found}")
    
    print(f"\nüé® PATTERNS:")
    print(f"   Valid: {patterns_result['valid']}")
    print(f"   Total: {len(patterns_result.get('patterns', []))}")
    for p in patterns_result.get('patterns', []):
        print(f"   - {p['pattern_category']}: {p['pattern_name']} ({p['confidence']:.2f})")
    
    print(f"\nüîó CAUSAL CHAINS:")
    print(f"   Valid: {chains_result['valid']}")
    print(f"   Total: {len(chains_result.get('chains', []))}")
    for c in chains_result.get('chains', []):
        print(f"   - {c['process_category']}: {len(c['stages'])} stages ({c['confidence']:.2f})")
        for stage in c['stages'][:3]:  # –ü–µ—Ä–≤—ã–µ 3 —ç—Ç–∞–ø–∞
            print(f"      {stage['stage']}. {stage['stage_name']}")
    
    print(f"\nüèóÔ∏è HIERARCHY:")
    print(f"   Valid: {hierarchy_result['valid']}")
    if hierarchy_result['valid']:
        h = hierarchy_result['hierarchy']
        print(f"   Root: {h['root']['name']}")
        print(f"   Domains: {len(h['domains'])}")
        print(f"   Practices: {len(h['practices'])}")
        print(f"   Techniques: {len(h['techniques'])}")
        print(f"   Exercises: {len(h['exercises'])}")
        print(f"   Cross-connections: {len(h['cross_connections'])}")
    
    print("\n" + "="*80)