#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
"""

import time
import logging
from pathlib import Path
import sys
import json

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from vector_db import VectorDBManager, EmbeddingService, VectorIndexer
import yaml

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s'
)
logger = logging.getLogger(__name__)


def test_vectorization_speed():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config_path = Path("config.yaml")
    if not config_path.exists():
        logger.error(f"‚ùå –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")
        return
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    logger.info("=" * 80)
    logger.info("üß™ –¢–ï–°–¢ –°–ö–û–†–û–°–¢–ò –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–ò")
    logger.info("=" * 80)
    
    # –í—ã–≤–æ–¥ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    rate_config = config['vector_db']['rate_limiting']
    logger.info(f"\nüìã –¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    logger.info(f"   chunk_size: {rate_config['chunk_size']}")
    logger.info(f"   delay_between_requests: {rate_config['delay_between_requests']}s")
    logger.info(f"   max_workers: {rate_config['max_workers']}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    db_manager = VectorDBManager(
        db_path=config['vector_db']['db_path'],
        collection_prefix=config['vector_db']['collection_prefix']
    )
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ rate limiting –∏–∑ config
    rate_limiting = config['vector_db'].get('rate_limiting', {})
    text_processing = config['vector_db'].get('text_processing', {})
    embedding_service = EmbeddingService(
        model=config['vector_db']['embedding']['model'],
        chunk_size=rate_limiting.get('chunk_size', 2048),
        delay_between_requests=rate_limiting.get('delay_between_requests', 0.5),
        max_retries=rate_limiting.get('max_retries', 5),
        retry_delay=rate_limiting.get('retry_delay', 2.0),
        max_retry_delay=rate_limiting.get('max_retry_delay', 60.0),
        max_tokens_per_text=text_processing.get('max_tokens_per_text', 8000),
        chunk_overlap=text_processing.get('chunk_overlap', 100),
        max_workers=rate_limiting.get('max_workers', 3)
    )
    
    indexer = VectorIndexer(
        db_manager=db_manager,
        embedding_service=embedding_service,
        batch_size=config['vector_db'].get('batch_size', 100)
    )
    
    # –ü–æ–∏—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
    sag_final_dir = Path("data/sag_final")
    test_files = list(sag_final_dir.glob("*.for_vector.json"))
    
    if not test_files:
        logger.error("‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ data/sag_final/")
        return
    
    test_file = test_files[0]
    logger.info(f"\nüìÑ –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {test_file.name}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    with open(test_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    blocks_count = len(data.get('blocks', []))
    graph_entities_count = len(data.get('graph_entities', []))
    documents_count = 1 if data.get('document_title') or data.get('document_summary') else 0
    
    logger.info(f"   üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {documents_count}")
    logger.info(f"   üìä –ë–ª–æ–∫–æ–≤: {blocks_count}")
    logger.info(f"   üìä –ì—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–µ–π: {graph_entities_count}")
    logger.info(f"   üìä –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {documents_count + blocks_count + graph_entities_count}")
    
    # –û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–æ–º
    logger.info(f"\nüßπ –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π...")
    for level in ['documents', 'blocks', 'graph_entities']:
        try:
            db_manager.delete_collection(level)
            logger.debug(f"   –£–¥–∞–ª–µ–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è: {level}")
        except Exception as e:
            logger.debug(f"   –ö–æ–ª–ª–µ–∫—Ü–∏—è {level} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}")
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
    logger.info(f"\n‚è±Ô∏è  –ù–ê–ß–ê–õ–û –ò–ù–î–ï–ö–°–ê–¶–ò–ò...")
    logger.info("=" * 80)
    
    start_time = time.time()
    
    result = indexer.index_sag_file(
        test_file,
        index_levels=['documents', 'blocks', 'graph_entities']
    )
    
    elapsed = time.time() - start_time
    
    logger.info("=" * 80)
    logger.info(f"‚è±Ô∏è  –ò–ù–î–ï–ö–°–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
    logger.info("=" * 80)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    logger.info(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    logger.info(f"   ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {elapsed:.2f} —Å–µ–∫—É–Ω–¥")
    
    total_items = sum([
        result.get('indexed', {}).get('documents', 0),
        result.get('indexed', {}).get('blocks', 0),
        result.get('indexed', {}).get('graph_entities', 0)
    ])
    
    if total_items > 0 and elapsed > 0:
        speed = total_items / elapsed
        logger.info(f"   ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {speed:.1f} —ç–ª–µ–º–µ–Ω—Ç–æ–≤/—Å–µ–∫")
    else:
        logger.warning(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å (—ç–ª–µ–º–µ–Ω—Ç–æ–≤: {total_items}, –≤—Ä–µ–º—è: {elapsed:.2f}s)")
    
    if result['success']:
        logger.info(f"   ‚úÖ –°—Ç–∞—Ç—É—Å: –£–°–ü–ï–®–ù–û")
        logger.info(f"   üìÑ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {result.get('indexed', {}).get('documents', 0)}")
        logger.info(f"   üì¶ –ë–ª–æ–∫–æ–≤: {result.get('indexed', {}).get('blocks', 0)}")
        logger.info(f"   üï∏Ô∏è  –ì—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–µ–π: {result.get('indexed', {}).get('graph_entities', 0)}")
    else:
        logger.error(f"   ‚ùå –°—Ç–∞—Ç—É—Å: –û–®–ò–ë–ö–ê")
        logger.error(f"   ‚ùå –î–µ—Ç–∞–ª–∏: {result.get('error', 'Unknown')}")
    
    # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    logger.info(f"\nüéØ –û–¶–ï–ù–ö–ê –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
    if elapsed < 2:
        logger.info(f"   üöÄ –û–¢–õ–ò–ß–ù–û! –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è (< 2 —Å–µ–∫)")
    elif elapsed < 10:
        logger.info(f"   ‚úÖ –•–û–†–û–®–û! –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±—ã—Å—Ç—Ä–∞—è (< 10 —Å–µ–∫)")
    elif elapsed < 30:
        logger.info(f"   ‚ö†Ô∏è  –°–†–ï–î–ù–ï! –ú–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å (< 30 —Å–µ–∫)")
    else:
        logger.info(f"   ‚ùå –ú–ï–î–õ–ï–ù–ù–û! –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (> 30 —Å–µ–∫)")
    
    logger.info(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if elapsed > 10:
        logger.info(f"   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ vector_indexer.py")
        logger.info(f"   2. –£–º–µ–Ω—å—à–∏—Ç–µ delay_between_requests –¥–æ 0.5s –≤ config.yaml")
        logger.info(f"   3. –£–≤–µ–ª–∏—á—å—Ç–µ max_workers –¥–æ 3 –≤ config.yaml")
    else:
        logger.info(f"   ‚úÖ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ!")


if __name__ == "__main__":
    test_vectorization_speed()

