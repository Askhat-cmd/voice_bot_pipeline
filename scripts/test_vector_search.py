#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
"""

import argparse
import json
import logging
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from vector_db import VectorDBManager, EmbeddingService, VectorSearch
import yaml

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s"
)
logger = logging.getLogger(__name__)


def print_search_results(results: list, result_type: str):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
    if not results:
        print(f"\n‚ùå {result_type}: —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return
    
    print(f"\n‚úÖ {result_type}: –Ω–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("-" * 80)
    
    for i, result in enumerate(results, 1):
        print(f"\n[{i}] ID: {result['id']}")
        print(f"    –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {result.get('distance', 'N/A'):.4f}")
        
        metadata = result.get('metadata', {})
        if metadata:
            print(f"    –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
            for key, value in list(metadata.items())[:5]:  # –ü–µ—Ä–≤—ã–µ 5 –ø–æ–ª–µ–π
                print(f"      - {key}: {value}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        document = result.get('document', '')
        if document:
            preview = document[:200] + "..." if len(document) > 200 else document
            print(f"    –¢–µ–∫—Å—Ç: {preview}")


def main():
    parser = argparse.ArgumentParser(
        description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î"
    )
    parser.add_argument(
        "--config",
        default="config.yaml",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: config.yaml)"
    )
    parser.add_argument(
        "--query",
        required=True,
        help="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"
    )
    parser.add_argument(
        "--type",
        choices=["documents", "blocks", "graph_entities", "hybrid", "test_embeddings"],
        default="hybrid",
        help="–¢–∏–ø –ø–æ–∏—Å–∫–∞ –∏–ª–∏ —Ç–µ—Å—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: hybrid). 'test_embeddings' - —Ç–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=5,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)"
    )
    parser.add_argument(
        "--filter",
        help="–§–∏–ª—å—Ç—Ä –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON (–Ω–∞–ø—Ä–∏–º–µ—Ä: '{\"video_id\": \"xxx\"}')"
    )
    
    args = parser.parse_args()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config_path = Path(args.config)
    if not config_path.exists():
        logger.error(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")
        return 1
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    if 'vector_db' not in config:
        logger.error("–°–µ–∫—Ü–∏—è vector_db –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ config.yaml")
        return 1
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    try:
        db_manager = VectorDBManager(
            db_path=config['vector_db']['db_path'],
            collection_prefix=config['vector_db']['collection_prefix']
        )
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ rate limiting –∏–∑ config (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        rate_limiting = config['vector_db'].get('rate_limiting', {})
        text_processing = config['vector_db'].get('text_processing', {})
        embedding_service = EmbeddingService(
            model=config['vector_db']['embedding']['model'],
            chunk_size=rate_limiting.get('chunk_size', 2048),
            delay_between_requests=rate_limiting.get('delay_between_requests', 15.0),
            max_retries=rate_limiting.get('max_retries', 5),
            retry_delay=rate_limiting.get('retry_delay', 2.0),
            max_retry_delay=rate_limiting.get('max_retry_delay', 60.0),
            max_tokens_per_text=text_processing.get('max_tokens_per_text', 8000),
            chunk_overlap=text_processing.get('chunk_overlap', 100),
            max_workers=rate_limiting.get('max_workers', 1)
        )
        search = VectorSearch(
            db_manager=db_manager,
            embedding_service=embedding_service
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}", exc_info=True)
        return 1
    
    # –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    filters = None
    if args.filter:
        try:
            filters = json.loads(args.filter)
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤: {e}")
            return 1
    
    # –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    if args.type == "test_embeddings":
        print(f"\nüß™ –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
        print(f"üìù –¢–µ–∫—Å—Ç: '{args.query}'")
        print("=" * 80)
        
        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            print("\n‚è≥ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞...")
            embedding = embedding_service.create_embedding(args.query)
            
            print(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
            print(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(embedding)}")
            print(f"üìà –ü–µ—Ä–≤—ã–µ 10 –∑–Ω–∞—á–µ–Ω–∏–π: {embedding[:10]}")
            print(f"üìâ –ú–∏–Ω–∏–º—É–º: {min(embedding):.6f}, –ú–∞–∫—Å–∏–º—É–º: {max(embedding):.6f}")
            print(f"üìä –°—Ä–µ–¥–Ω–µ–µ: {sum(embedding)/len(embedding):.6f}")
            
            # –¢–µ—Å—Ç –±–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∏
            test_texts = [
                args.query,
                "–≠—Ç–æ –≤—Ç–æ—Ä–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∏",
                "–¢—Ä–µ—Ç–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
            ]
            print(f"\n‚è≥ –¢–µ—Å—Ç –±–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∏ ({len(test_texts)} —Ç–µ–∫—Å—Ç–æ–≤)...")
            batch_embeddings = embedding_service.create_embeddings_batch(test_texts)
            
            print(f"‚úÖ –ë–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            print(f"üìä –°–æ–∑–¥–∞–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(batch_embeddings)}")
            for i, emb in enumerate(batch_embeddings, 1):
                print(f"  [{i}] –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(emb)}, –°—Ä–µ–¥–Ω–µ–µ: {sum(emb)/len(emb):.6f}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            output_file = Path("embedding_test_results.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "query": args.query,
                    "single_embedding": {
                        "dimension": len(embedding),
                        "first_10_values": embedding[:10],
                        "stats": {
                            "min": min(embedding),
                            "max": max(embedding),
                            "mean": sum(embedding)/len(embedding)
                        }
                    },
                    "batch_embeddings": {
                        "count": len(batch_embeddings),
                        "dimensions": [len(emb) for emb in batch_embeddings]
                    }
                }, f, indent=2, ensure_ascii=False)
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
            
            print("\n" + "=" * 80)
            print("‚úÖ –¢–µ—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            return 0
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}", exc_info=True)
            return 1
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞
    print(f"\nüîç –ü–æ–∏—Å–∫: '{args.query}'")
    print(f"üìä –¢–∏–ø: {args.type}")
    print(f"üìà Top-K: {args.top_k}")
    if filters:
        print(f"üîß –§–∏–ª—å—Ç—Ä—ã: {filters}")
    print("=" * 80)
    
    try:
        if args.type == "documents":
            results = search.search_documents(args.query, top_k=args.top_k, filters=filters)
            print_search_results(results, "–î–æ–∫—É–º–µ–Ω—Ç—ã")
            
        elif args.type == "blocks":
            results = search.search_blocks(args.query, top_k=args.top_k, filters=filters)
            print_search_results(results, "–ë–ª–æ–∫–∏")
            
        elif args.type == "graph_entities":
            results = search.search_graph_entities(args.query, top_k=args.top_k, filters=filters)
            print_search_results(results, "–ì—Ä–∞—Ñ-—Å—É—â–Ω–æ—Å—Ç–∏")
            
        elif args.type == "hybrid":
            results = search.hybrid_search(args.query, top_k=args.top_k, filters=filters)
            print("\n‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫: –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π")
            print("-" * 80)
            
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
            by_source = {}
            for result in results:
                source = result.get('source', 'unknown')
                if source not in by_source:
                    by_source[source] = []
                by_source[source].append(result)
            
            for source, source_results in by_source.items():
                print(f"\nüì¶ {source.upper()}: {len(source_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                for i, result in enumerate(source_results[:3], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                    print(f"  [{i}] {result['id']} (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {result.get('normalized_distance', 'N/A'):.4f})")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON
            output_file = Path("search_results.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "query": args.query,
                    "type": args.type,
                    "top_k": args.top_k,
                    "filters": filters,
                    "results": results
                }, f, indent=2, ensure_ascii=False)
            print(f"\nüíæ –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
        
        print("\n" + "=" * 80)
        print("‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–æ–∏—Å–∫–∞: {e}", exc_info=True)
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

